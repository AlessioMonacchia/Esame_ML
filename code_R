#### Libraries ####

library(terra)
library(pROC)
library(caret)
library(sf)
library(purrr)
library(tools)
library(tidyverse)
library(rsample)
library(furrr)
library(pbapply)
library(ranger)
library(tidymodels)
library(e1071)
library(ggridges)
library(gridExtra)
library(rlang)
library(rpart.plot)
# library(rgl)
library(scatterplot3d)
library(RVAideMemoire)
library(rstatix)

#### Functions ####

source("R/clean.name.R") # scorciatoia per:

clean_name <- function(file) {
  
  var_name <- tools::file_path_sans_ext(basename(file))   # get file name without extension
  
  var_name <- gsub("[^[:alnum:]_]", "", var_name)
  
  if (grepl("^[0-9]", var_name)) {
    
    var_name <- paste0("x, var_name")
    
  }
  
  var_name
  
}


ridgeplot <- function(dataframe, x.variable, y.variable){
  
  ridge <- ggplot(dataframe, aes(x.variable, y.variable, fill = factor(stat(quantile)))) +
    
    stat_density_ridges(
      
      geom = "density_ridges_gradient", calc_ecdf = TRUE,
      
      quantiles = 4, quantile_lines = TRUE
      
    )
  
}


model_scores <- function(model_predictions, response_variable){
  
  matrice_confusione <- confusionMatrix(model_predictions, response_variable, positive = "fiore")
  
  accuracy <- matrice_confusione$overall['Accuracy']
  
  recall <- matrice_confusione$byClass["Sensitivity"]
  
  f1 <- matrice_confusione$byClass["F1"]
  
  auc_roc <- roc(test_data$label, as.numeric(model_predictions))
  
  auc <- auc(auc_roc)
  
  precision <- matrice_confusione$byClass["Pos Pred Value"]
  
  
  
  print(matrice_confusione)
  
  print(paste("Accuracy: ", accuracy))
  
  print(paste("Recall: ", recall))
  
  print(paste("F1-score: ", f1))
  
  print(paste("AUC-ROC", auc))
  
  print(paste("Precision: ", precision))
  
}

#### Import data ####

setwd("C:/Esame_ML")

# orthomosaics

ortho <- list.files(pattern = "Ortho", full.names = TRUE, recursive = TRUE)%>%
  
  set_names(nm = map(., clean_name)) %>%
  
  map(~rast(.))

ortho <- ortho[1:3]

# buffers

buffers <- list.files(pattern = "buffer.*shp",
                      
                      full.names = TRUE, recursive = TRUE)%>%
  
  set_names(nm = map(., clean_name))%>%
  
  map(~st_read(.))

buffers <- buffers[1:3]


# Fiori ed Erba

fiori <- list.files(pattern = "fiori.*shp", full.names = TRUE, recursive = TRUE)%>%
  
  set_names(nm =map(., clean_name)) %>%
  
  map(~st_read(.))%>%
  
  map(~.[!st_is_empty(.), ])

fiori <- fiori[1:3]


erba <- list.files(pattern = "erba.*shp", full.names = TRUE, recursive = TRUE)%>%
  
  set_names(nm = map(., clean_name)) %>%
  
  map(~st_read(.))%>%
  
  map(~.[!st_is_empty(.), ])                # linea di codice che esclude le geometrie vuote

erba <- erba[1:3]



#### Image pre-processing ####

# crop orthomosaics within buffer extentions

ortho <- map2(ortho, map(buffers, ~ ext(.x)), ~ crop(.x, .y))

# mask orthomosaics within buffer extentions

ortho <- map2(ortho, buffers, ~ mask(.x, .y))

# values extraction

values_fiori <- map2(ortho, fiori, ~terra::extract(.x, .y))

values_erba <- map2(ortho, erba, ~terra::extract(.x, .y))

# change column names for each element of the lists

df_fiori <- map(values_fiori, ~{
  
  colnames(.) <- c("ID_poly", paste0("banda_", 1:(ncol(.)-1)))
  
  .
  
})

df_erba <- map(values_erba, ~{
  
  colnames(.) <- c("ID_poly", paste0("banda_", 1:(ncol(.)-1)))
  
  .
  
})

# convert into dataframes

df_fiori_unified <- bind_rows(df_fiori, .id = "origin")   # .id = "origin": Questo argomento opzionale viene utilizzato per aggiungere 
# una colonna chiamata "origin" al risultato finale. 
# Questa colonna conterrÃ  il nome dell'oggetto (in questo caso, il dataframe) 
# da cui proviene ogni riga.

df_erba_unified <- bind_rows(df_erba, .id ="origin")

# add the label column to the data frames

df_fiori_unified$label <- "fiore"

df_erba_unified$label <- "erba"


#### Exploratory data analysis ####

# using ggridges for the density plots

df_tot <- rbind(df_fiori_unified, df_erba_unified) %>%
  
  rowid_to_column(.) %>% 
  
  rename(ID_pixel = rowid)


# Seleziono le bande

set.seed(123)


# Crea un nuovo dataframe con solo le colonne che vuoi usare

sum(is.na(df_tot))


df_selected <- df_tot %>%
  
  select(banda_1, banda_2, banda_3, label) %>%
  
  na.omit()


# calculate the main summary statistics

summary(df_erba_unified)

summary(df_fiori_unified)


# calcualte the interquantile range

IQR(df_fiori_unified)


# Ridgeplots

ridge1 <- ridgeplot(df_selected, df_selected$banda_1, df_selected$label)

ridge2 <- ridgeplot(df_selected, df_selected$banda_2, df_selected$label)

ridge3 <- ridgeplot(df_selected, df_selected$banda_3, df_selected$label)

grid.arrange(ridge1, ridge2, ridge3, ncol = 2)


# scatterplot: variables relation

pairs(df_fiori_unified[,3:5], pch = 19)

pairs(df_erba_unified[,3:5], pch = 19)


# Provo il 3D plot

df_3D <- df_selected[c(1:10000), ]

# Add a new column with color
# mycolors <- c('royalblue1', 'oldlace')

# df_3D$color <- mycolors[ as.numeric(df_selected$label) ]

df_3D$color <- NA

df_3D_f <- which(df_3D$label == "fiore", )

df_3D_e <- which(df_3D$label == "erba", )

df_3D$color[df_3D_f] <- "red"

df_3D$color[df_3D_e] <- "green"

# Plot attempt with rgl package
# plot3d( x=df_3D$banda_1, y=df_3D$banda_2, z=df_3D$banda_3,
#   col = df_3D$color, 
#   size = 1,
#   type = 's',
#   radius = .1,
#   xlab="band 1", ylab="band 2", zlab="band 3")

# To display in an R Markdown document:
# rglwidget()

# To save to a file:
# htmlwidgets::saveWidget(rglwidget(width = 520, height = 520), 
#                         file = "HtmlWidget/3dscatter.html",
#                         libdir = "libs",
#                         selfcontained = FALSE
# )

# Attempt with scatterplot3D package

scatterplot3d(
  df_3D[,1:3], 
  pch = 16, 
  color = df_3D$color,
  type = "h",
  grid=TRUE, box=T)
legend("bottom", legend = levels(df_3D$label),
       col =  c("red", "green"), 
       pch = c(16), 
       inset = -0.25, xpd = TRUE, horiz = TRUE)

#### Data split ####

# Dividi il dataframe selezionato in set di addestramento e di test

data_split <- initial_split(df_selected, prop = 0.7, strata = "label")

training_data <- training(data_split)

test_data <- testing(data_split)


summary(training_data)
summary(test_data)

# Convertiamo in un fattore

training_data$label <- as.factor(training_data$label)

test_data$label <- as.factor(test_data$label)


#### RF Model ####

# Define cross-validation strategy

train_control <- trainControl(method = "cv", number = 5,
                              
                              savePredictions = "final",
                              
                              verboseIter = TRUE)


# Train the model using ranger and the tuning grid

# Calcola i pesi delle classi

classi <- unique(training_data$label)

class_weights <- c("erba" = 0.1, "fiore" = 0.9)


# Define tuning parameters

RFGrid <- expand.grid(mtry = c(1, 2, 3),
                        
                        splitrule = "hellinger",
                        
                        min.node.size = c(1, 3, 5))


# Addestra il modello utilizzando i pesi delle classi

RF <- train(label ~ ., 
            
            data = training_data,
            
            method = "ranger",
            
            num.trees = 500,
            
            trControl = train_control,
            
            tuneGrid = RFGrid,
            
            class.weights = class_weights)


plot(RF)

print(RF)


#### K-nearest neighbor model ####

# Tuning parameters

KNNGrid <- expand.grid(k = c(3, 5, 10))


# Addestra il modello utilizzando i pesi delle classi

KNN <- train(label ~ ., 
            
            data = training_data,
            
            method = "knn",
            
            trControl = train_control,
            
            tuneGrid = KNNGrid)



#### Support Vector Machines model ####

# tuning parameters

SVMGrid <- expand.grid(cost = c(5, 10, 15, 20, 50))


# Addestra il modello utilizzando i pesi delle classi

SVM <- train(label ~ ., 
             
             data = training_data,
             
             method = "svmLinear2",
             
             trControl = train_control,
             
             tuneGrid = SVMGrid,
             
             class.weights = class_weights)


#### NNE Model ####

# comprehensible alternative

NNE_grid <- expand.grid(decay = c(0.5, 1e-2, 1e-3), # weight decay
                         
                         size = c(2, 5, 10)) # number of hidden units


# Train the neural network using train()

set.seed(123)

NNE <- train(label ~ ., 
                  
                  data = training_data, 
                  
                  method = "nnet",
                  
                  trControl = train_control,
                  
                  tuneGrid = NNE_grid, 
                  
                  class.weights = class_weights)


# Print the trained model

plot(NNE)

print(NNE)

### Model Assessment ####

predizioni_RF <- predict(RF, test_data)

predizioni_KNN <- predict(KNN, test_data)

predizioni_SVM <- predict(SVM, test_data)

predizioni_NNE <- predict(NNE, test_data)


scores_RF <- model_scores(predizioni_RF, test_data$label)

scores_kNN <- model_scores(predizioni_KNN, test_data$label)

scores_SVM <- model_scores(predizioni_SVM, test_data$label)

scores_NNE <- model_scores(predizioni_NNE, test_data$label)


#### Model Comparison ####

# For multiple comparisons
# Prapare the data for the Cochran's Q test

model1 <- data.frame(
  outcome = ifelse(as.vector(predizioni_RF) >= as.vector(test_data$label), 1, 0),
  algorithm = gl(1, length(predizioni_RF), length(predizioni_RF), labels = "RF"),
  ID = 1:length(predizioni_RF))

model2 <- data.frame(
  outcome = ifelse(as.vector(predizioni_KNN) >= as.vector(test_data$label), 1, 0),
  algorithm = gl(1, length(predizioni_KNN), length(predizioni_KNN), labels = "KNN"),
  ID = 1:length(predizioni_KNN))

model3 <- data.frame(
  outcome = ifelse(as.vector(predizioni_SVM) >= as.vector(test_data$label), 1, 0),
  algorithm = gl(1, length(predizioni_SVM), length(predizioni_SVM), labels = "SVM"),
  ID = 1:length(predizioni_SVM))

model4 <- data.frame(
  outcome = ifelse(as.vector(predizioni_NNE) >= as.vector(test_data$label), 1, 0),
  algorithm = gl(1, length(predizioni_NNE), length(predizioni_NNE), labels = "NNE"),
  ID = 1:length(predizioni_NNE))


# Bind in a single dataframe

Test <- rbind(model1, model2, model3, model4)


# convert the outcome into a factor with 2 levels

Test$outcome <- factor(
  
  Test$outcome, levels = c(1, 0),
  
  labels = c("success", "failure")
  
)


# Cross-tabulation: create a contingency table from cross-classifying factors

xtabs(~outcome + algorithm, Test)


# Then apply the Cochran's Q test

cochran.qtest(outcome ~ algorithm|ID, Test)


# Then apply the pairwise McNemar test

pairwise_mcnemar_test(Test, outcome ~ algorithm|ID)

# OR

# pairwise_mcnemar_test(data,
#  formula,
#  type = c("mcnemar", "exact"),
#  correct = TRUE,
#  p.adjust.method = "bonferroni"
#)

#### Raster creation ####

# aggiustiamo i nomi

ortho$Ortho_BE1$`Ortho_BE1_4` <- NULL

ortho <- map(ortho, function(x) {
  
  names(x) <- colnames(df_selected)[1:3]
  
  return(x)
  
})



# Creare una lista vuota per memorizzare i risultati

classificazione_RF_list <- list()

# Ciclo for per applicare predizioni modelli a tutti gli elementi di ortho

for (name in names(ortho)) {
  
  previsioni <- terra::predict(ortho[[name]], nn_model, na.rm = TRUE)
  
  classificazione_RF_list[[name]] <- previsioni

}


# Salvare la classificazione in formato GeoTiff

names(classificazione_RF_list) <- names(ortho) # Assicuriamoci che i nomi corrispondano


walk(names(classificazione_RF_list), function(name) {
  
  terra::writeRaster(classificazione_RF_list[[name]],
                     
                     filename = paste0(name, ".tif"),
                     
                     overwrite = TRUE)
  
})


# Per NNe


classificazione_NN_list <- list()

# Ciclo for per applicare predizioni modelli a tutti gli elementi di ortho

for (name in names(ortho)) {
  
  previsioni <- terra::predict(ortho[[name]], nn_model, na.rm = TRUE)
  
  classificazione_NN_list[[name]] <- previsioni
  
}


# Salvare la classificazione in formato GeoTiff

names(classificazione_NN_list) <- names(ortho) # Assicuriamoci che i nomi corrispondano


walk(names(classificazione_NN_list), function(name) {
  
  terra::writeRaster(classificazione_NN_list[[name]],
                     
                     filename = paste0(name, ".tif"),
                     
                     overwrite = TRUE)
  
})
